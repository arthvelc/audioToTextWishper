{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "18MFp51ld6dQFn7PosKH4pH_8dQQWy6jf",
      "authorship_tag": "ABX9TyP5pqPkTBneP/cIUnLkjQvN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthvelc/audioToTextWishper/blob/master/audioToTextWhisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pejgAtlMDi06"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsSJODRutj4c",
        "outputId": "f2073095-6108-4932-c0e7-ffc3b1f29116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-u3kw19rk\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-u3kw19rk\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.15.3)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802823 sha256=c060e7efe97152deaf2b79cd1c1655fbad11f81c5ef2dce7e2f436a4123180d2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0aou0gz1/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update && sudo apt install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVNJz3LZwfkB",
        "outputId": "2fa6f08b-92c9-49c9-e7b3-71a4ab1a14a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [929 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,556 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,189 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,393 kB]\n",
            "Fetched 7,330 kB in 3s (2,242 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "45 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrevistas"
      ],
      "metadata": {
        "id": "o4Fppd6s5RnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"medium\")\n",
        "result = model.transcribe(\"/content/saihon retro 2.m4a\")"
      ],
      "metadata": {
        "id": "-Jz9WXtixY1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e30d3bb8-a20e-47c9-cc54-b1edec6b26b0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:65: UserWarning: /root/.cache/whisper/medium.pt exists, but the SHA256 checksum does not match; re-downloading the file\n",
            "  warnings.warn(\n",
            "100%|██████████████████████████████████████| 1.42G/1.42G [00:15<00:00, 101MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4tlwbb1xpW3",
        "outputId": "fe4494e0-eed5-4fe0-831b-999f35c14eb7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Gracias equipo. Este, hay un detalle que lo hubiese dejado pasar como en el equipo anterior porque también se vio en el equipo anterior, pero no quiero que se siga pasando de equipo a equipo. Entonces es muy importante esta parte. Cuando ustedes van a una cita, y vamos a imaginar que es una cita ciegas y conocen a la persona, y ustedes no se sientan y dicen, ¿sabes qué? Nada más que no me gusta bañarme los domingos, yo no cocino, yo no hago esto, estoy intentando aprender a usar la lavadora. No llegan y hacen eso, porque nos han dicho todo el mundo, si te dice eso, la primera cita es una resla. Funciona igual acá en el proyecto. Entonces, si usted está diciendo, no más que todavía no ponemos esto, o todavía no agregamos esto, o vamos a tener esto, etcétera. Y si por algún motivo, razón o circunstancia no dan los tiempos, y yo a la siguiente presentación les digo, ustedes aquí me prometieron esto, ¿qué pasó? ¿Para qué lo prometimos en aquel entonces? Que tal vez los tiempos ya no nos dieron. Entonces les digo, fue a un punto que vi en el cuando yo aquí estoy viendo acá. Es muy importante como no decir lo que no tenemos. Porque si tienen bastante, ahorita justo iba a decir esto, tienen bastante ya establecido para que lo que no tienen sale de sobra. Entonces cuando ustedes dicen, no falta esto, esto y aquello, eso sale de sobra. Esa parte del discurso yo les recomendaría contarlo. Por otra parte, Braulio, ¿tú fuiste el que empezó el discurso, verdad? No, ¿quién empezó? No, fue Arturo. Me agrada la voz del locutor que haces al inicio. Funciona, funciona perfectamente, llama la atención, hace un clic en el cerebro en el que se pone la atención. Oye, pero es su voz, o sea, no es que la haga, es su voz. Sí, lo sé, es mi mente. Me agrada, llamas la atención, el foco, eso es bueno. Excelente jugada equipo, ponerlo como para abrir el discurso. Oye, también se va, lo digo. Estuvo muy llana, se ve muchísimo mejor su header, su acá su cabecita, todo lo que dice aquí, su franja negra, sí, se ve muy lindo. Esas pequeñas líneas en mi punto de vista hicieron un cambio muy grande. Esto que ustedes agregaron hizo un cambio muy significativo y me agrada, se ve bonito, o sea, hace que se vea bonito, hace un pequeño contraste y al momento le da armonía con el resto de la página. Entonces, está muy bien. ¿Hay una pequeña y ligera sombra aquí? ¿Y entre los libros? No, aquí no habría sombra. ¿De dónde había una? Porque vi que me gustaba esta imagen con una sombra y también se me hizo muy bonita. Pero yo no la digo. ¿Inicio, catálogo? No sé si te refieres a esta. A ver, estábamos en el inicio. Sí, estábamos en el inicio. ¿Dónde habrá sido? Porque ahorita se me hizo como que se veía como una sombra y me daba como un aspecto muy, muy agradante y se me hizo lindo. Sí, quién sabe si lo veo más adelante, lo digo. Sí, pero habría relacionado a su discurso, el discurso de ustedes y a esta parte que ya se ve muy bien. Y vi que en el menú de burguesa, cuando lo hacen pequeño, que también llenaron el espacio, ¿verdad? Sí, de hecho aquí estaría. Sí, me agrada. O sea, no lo recorrieron en el inicio, pero agregaron esto. O sea, fue una excelente solución. No está mal. O sea, está en el punto de vista, ¿verdad? Se me hace como que sí está bien. O sea, muchas gracias y sería todo. Gracias. Gracias, Sari. Voy, ok. Pongan porfa en responsiva la página en nosotros. Ponlo lo más pequeño. Ok, se dan cuenta que sus cats y su información están pegadas solo de un lado de la página. Ahora, ahí arribita donde les marca esa línea roja, ahí dice, ehh, un e-commerce con el objetivo de ofrecer una mejor experiencia a nuestros clientes al momento de comprar en libros en línea. Como que hay algo no me cuadra. Pues sí. Ok, entonces, chequen ahí ese, ese para que se lo quiten. Ok, vamos abajo, vamos abajo. Bien, bueno, eso ya, dale click a alguna de las cats, porfa. No, encima. Ah, encima, sí, cierto. Ah, ya sé que falta. Ah, mi compu está doyendo loca. ¿Qué es lo que pasa? Subele un poquito para que pueda ver. Arriba, arriba. No sé si me escuchan, pero bueno, aquí mi computadora como que de pronto. Ya la vimos, ya se puso la dita. Ya, sí. Más arriba, más, más, más. No, no, no, ahí pícale alguna. Ah, ok. A cart, así. Se sigue encimando, es que es lo que no alcanzo a ver. Eh, con el borde, eh, no realmente. Sólo que aquí tenemos un detalle porque en algunas páginas no sabríamos decir si, por ejemplo, esta parte del, del, ay, como del cursor del scroll, sí afecta como tal al responsivo o no. No, te voy a decir por qué no, porque tienen otra página. Vete a tu menú. Ajá. Al de, a ver, acá está. Vete a catálogo. Ok. Y ponle en responsivo, lo más pequeño todavía. Solamente pasa con, con las cartes que tienen, ya viste? Ok. Vete al inicio. Y ya viste? Ahí no hay como tal, pero qué pasa con su footer? Sí. O sea, ahí como tal el scroll no afecta la parte de arriba, pero sí está afectando su footer. Ok. Más. Ese imagen que tienen ahí en Desayon se, se ve muy arriba. Entonces, como que se corta el texto, ya se dieron cuenta? Ajá. Con el menú. Y otra cosa, ya saben que yo estoy bien ciega, no? Pero cieguísima. Ok. Y si no hay más cartas populares, no veo. Ah, ok. De, en cuanto al catálogo de libros. Exactamente. Yo veo unos pequeños cuadritos como rosa, azul, esos, pero no alcanzo a ver más. Sí. Va. Espérame. ¿Por qué? Por acá tenía otra. Sólo dejo ver dónde la abrí. Ok. No. Lo vemos igual. Ok. Si quieres, déjale, ponle una más grande. Que es la de 425. Ándale ahí. Ah, pero. Eso no debería de pasar, no? Bueno. Ahí. Ok. Ese contacto no está muy hacia un lado. Vete más abajo. Ahí ya su botón se muestra bien. No hay ningún problema. Digo, la verdad es que las medidas estándar de los teléfonos ahora son de 425 para arriba. No dudo quién tenga una chacharrita. No todavía más chiquita y pueda desplegarla. Pero pues ahí se supone que debería de verse igual para 320 y para 425. Si ustedes establecen como punto de quiebre hasta el 425 como máximo, pues ahí debería de tener. Perdón. Como mínimo ahí debería de mantenerse igual. Y pues el contacto nos hace darnos cuenta que no está centrado, ¿no? Hasta hacia dónde está. Sí. Sí, está hasta la derecha. Ok. Ok. De lo de su inicio de sesión, no es que no esté centrado. No es que no esté centrado. De lo de su inicio de sesión, no les voy a decir nada porque aclararon que están trabajando en él. No. Justo les iba a decir que sí me inicia sesión, pero por ejemplo no hay nada que me indique si la puedo cerrar y tampoco nada que me indique si ya estoy dentro. Entonces supongo que eso es lo que están trabajando. Y si vamos al menú y lo despliegas, porfa. Ok. Sí, aquí tenemos donde está. ¿Cuál es? Es el tamaño del... Exacto. Carrito. Exactamente. Yo dije ese lunar rojo está muy bonito ahí, pero no sé qué sea. Entonces, obviamente ya cuando lo dicen grande, es que ustedes lo que no saben es que cuando yo abro sus archivos por lo regular, automáticamente me voy a hacer los responsivos. O sea, no los veo casi en desktop. Pero en este momento sí dije, ¡ah caray! Ya lo puse en desktop. Dije, pues es un carrito de compra. Pero, este, digo, nada más revisen eso, porfa. Muy bonito el logo que le agregaron. Me gusta bastante. El dragón. Igual yo le recomendaría. A lo mejor, quítenle el fondo. No sé quién lo diseñó. Está bonito. Quítenle el fondo y nada más enmarquenlo con un contorno blanco. Y háganlo más grande. Porque está bonito, pero no se aprecia completamente. Ok. Entonces, ¿eso podría ayudarles? Digo, para que resalten quién lo hizo. Y básicamente, eso es todo. Y, básicamente, es todo. Y, básicamente, es todo. Y, básicamente, eso es lo que yo he estado viendo. Y ahorita seguramente, Jason, también les voy a decir algo. Que se me esté pasando. Ah, les mandé el código para que corrigieran lo de la imagen. Que se pudiera seguir viendo. Que pasó con eso. Porque todavía me marca el error que en 1024 no se ve la imagen. Ah, ok. De ese lo estuvimos, bueno, lo queríamos trabajar ayer. Pero no comió el tiempo. No, no, no, no. No, no, no, no. No, no, no, no. No, no, no, no. Ven nomásimelo a copiar, ¿jo? Sí, entonces. Al lugar de decirle mis ahorros, les voy a decir mi tiempo, muchachos. Mi tiempo. No, así sí se aprecia. Y sí, sí leímos el código, pero si no ya... Ok, va. Entonces, iimplementelos, ¿no? Nada más sería eso y, pues listo. Jason, todos tuyos. Gracias, Ami. Yo ni había visto que era un dragón. ¿no? que bueno que lo menciona a mí. Pues miren, ya cambiaron ahí lo que les pedimos, los acentos en el nosotros quedó bien. Ya le agregaron el año de publicación cuando agregan un producto, perfecto. Cuando tienen un producto en su catálogo y tienen un botón de ver más. Y entonces le dan clic al botón de ver más, les muestra la información extra de cada uno de los libros. Y después tienen un botón de close y safe chain. No, creo que ya les habíamos comentado, tendría que ser un cerrar, cerrar por lo menos, no, nada más. El de guardar cambios, pues no sé cuáles cambios estamos guardando. No porque el safe chain, de dónde viene. Va con un botón de cerrar, quiten el safe chain y listo, a menos de que quieran agregar uno ahí, que sea agregar el carrito. Bueno, pues a lo mejor sí podría ir ahí ese segundo botón y agregaría el carrito, que sería lo mismo que se supone que va a ser el carrito que tiene cada uno de los libros. Va. Y entonces, ¿pueden ir al inicio de sesión, porfa? Digo, ahorita no sé por qué no puedo iniciar sesión. O sea, me refiero a ¿cuándo hicieron la tarea de iniciar sesión? Ayer, creo. ¿Ayer? ¿Cómo? ¿No se acuerdan? No me acuerdo. ¿Cómo lo estaban haciendo ustedes? Sí. ¿Por qué estaban haciendo? No, sí, sí. Técnicamente ya debería de estar. O sea, hoy técnicamente ya, hoy y mañana, cualquier equipo tendría que tener el inicio de sesión. Pero aparte de eso, ¿qué son los términos y condiciones? ¿Y qué es la política de tiempo? Porque aparte no tienen vínculos y no tienen acentos. No, pónganle vínculo y pónganle acento. Como lo mismo que le dije al otro equipo que no tenía vínculo a las políticas y los términos, que es inventen unas políticas, copienlas de alguien. No es una crisis didáctica. No importa. No van a ir un logrem y listo, ¿no? Va, pero que tenga un vínculo hacia donde están esas políticas y esos términos. Y bueno, ya les preguntó a mí que cómo sabemos que estamos logreados y oigan, ¿quitaron el menú estático que tenían en el catálogo el que no se movía? ¿Se acuerdan que en el catálogo cuando se si vas al catálogo y te desplazas hacia abajo? Ah, sí. Ok, está bien, no hay bronca. Pero ¿estas categorías de géneros y recomendaciones no funcionan? Sí, todavía no están linkeadas a la parte de, por ejemplo, bueno, la única que creo que estamos a linkear fue esta para que se aprecie. Y entonces manda acá. Pero... Los libros. Entonces, pues esa parte sí sería bueno que ya la tengan o le quitan, no le agregan las categorías porque funcionen, porque si no le dan clic y se ve medio raro. Porque si hubo una sola que sí me mandó a algún lado y todas las demás solamente actualizaba la parte. Ok, tengan cuidado con eso. Todo lo demás yo lo veo bien. No sabía que era un dragón. Está bien, ya subimos. Y pues listo. Perfecto. Entonces voy a detener la grabación. Recording stopped.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Script para mandar el string a un archivo .txt para manejar mejor la salida de texto.\n"
      ],
      "metadata": {
        "id": "yycqsWtEK7aY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "ruta = os.path.expanduser('./print.txt')\n",
        "\n",
        "with open(ruta, 'w', encoding= 'utf8') as archivo:\n",
        "  archivo.write(result['text'])"
      ],
      "metadata": {
        "id": "P1Fqbi-BKmYI"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}